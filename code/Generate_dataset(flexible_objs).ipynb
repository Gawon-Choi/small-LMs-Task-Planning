{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain=\"Kitchen\"\n",
    "\n",
    "OPENAI_API_KEY = # input your openai key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "gpt_model = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85902216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_object_inst(high_insts_list):\n",
    "    \n",
    "    ins_objs = list()\n",
    "    only_high_insts = list()\n",
    "    noise_prompt= list()\n",
    "\n",
    "    for idx, high_inst in enumerate(high_insts_list): # each instruction\n",
    "        parts = high_inst.strip().split(')')\n",
    "        \n",
    "        if len(parts) != 2:\n",
    "            print(\"There is abnormal format at all: \", high_inst)\n",
    "            noise_prompt.append(idx)\n",
    "            continue\n",
    "            \n",
    "        # objects\n",
    "        __ins_objs= parts[0].strip()\n",
    "        _ins_objs= __ins_objs.split(',')\n",
    "\n",
    "        for i, _objs in enumerate(_ins_objs):\n",
    "            _ins_objs[i]= re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', _objs)\n",
    "            _ins_objs[i]= _ins_objs[i].strip()\n",
    "        \n",
    "        # If there are more than 3 tokens, don't consider it an object\n",
    "        noise= list()\n",
    "        for obj in _ins_objs:\n",
    "            if obj.strip() == '':\n",
    "                _ins_objs.remove(obj)\n",
    "                continue\n",
    "                \n",
    "            token_count= obj.split(\" \")\n",
    "            if len(token_count) > 3:\n",
    "                _ins_objs.remove(obj)\n",
    "        \n",
    "        if _ins_objs==[]:\n",
    "            noise_prompt.append(idx)\n",
    "            continue\n",
    "\n",
    "        ins_objs.append(_ins_objs)\n",
    "#         print(_ins_objs)\n",
    "\n",
    "        # instruction\n",
    "        parts[1]= parts[1].strip()\n",
    "        parts[1]= re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', parts[1])\n",
    "        only_high_insts.append(parts[1])\n",
    "            \n",
    "    return ins_objs, only_high_insts, noise_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d717ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. If objects not in the object list is used when generating commands, add it to the list.\n",
    "def make_complete_objs(_objs, ins_objs):\n",
    "    objs= copy.deepcopy(_objs)\n",
    "\n",
    "    new_objs = [x.lower().strip() for x in ins_objs if x.lower().strip() not in objs]\n",
    "    new_objs= set(new_objs)\n",
    "    print('**new_objs:', new_objs, end=' ')\n",
    "    print('(len(new_objs):', len(new_objs), ')')\n",
    "    print('=================================', end='\\n\\n')\n",
    "    objs.extend(new_objs)\n",
    "    objs= list(set(objs))\n",
    "    \n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99285f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= './prompt_templates/flexible_objects/Commands_generating_prompt.txt'\n",
    "with open(file_path, 'r') as prompt_file:\n",
    "    command_prompt= prompt_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= './prompt_templates/flexible_objects/Action_steps_generating_prompt.txt'\n",
    "with open(file_path, 'r') as prompt_file:\n",
    "    steps_prompt= prompt_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa662c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read object list\n",
    "file_path= './datasets/{}/objects.json'.format(domain)\n",
    "with open(file_path, 'r') as objects_file:\n",
    "    _objects= json.load(objects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb4d13",
   "metadata": {},
   "source": [
    "------\n",
    "* Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee05516",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_dict= dict()\n",
    "commands_dict['place']= _objects['place']\n",
    "commands_dict['objects']= _objects['objects']\n",
    "commands_dict['used_objects']= list()\n",
    "commands_dict['prompt_output(high)']= list()\n",
    "commands_dict['high_instructions']= list()\n",
    "high_insts_list= list()\n",
    "\n",
    "file_path= './datasets/{}'.format(domain)\n",
    "commands_dict['objects']= [obj.lower() for obj in commands_dict['objects']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ef86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "iter_continue= True\n",
    "generate_num= 20\n",
    "dataset_size= 50000\n",
    "\n",
    "# First iteration block\n",
    "print(\"Start to generate high_instrctions. generated instructions: \", len(commands_dict['prompt_output(high)']))\n",
    "while True:\n",
    "    try:\n",
    "        ### Iteration stop condition\n",
    "        if dataset_size <= len(commands_dict['high_instructions']):\n",
    "            break\n",
    "            \n",
    "        iter_num+=1\n",
    "        _high_insts_list= list()\n",
    "\n",
    "        ### 1. Generate 20 high-level commands using objects list\n",
    "        prompt= command_prompt.format(domain, generate_num, commands_dict['objects'][:50])\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ]  \n",
    "\n",
    "        _response = openai.ChatCompletion.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages)\n",
    "        \n",
    "        # Output post-processing\n",
    "        _output = _response['choices'][0]['message']['content']\n",
    "        _high_insts= _output.strip()\n",
    "        _high_insts= '1. '+ _high_insts\n",
    "\n",
    "        sentences = _high_insts.split('\\n')\n",
    "        sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "        _high_insts_list = [re.sub(r'^\\d+\\.\\s*', '', sentence) for sentence in sentences]\n",
    "        \n",
    "        for idx, inst in enumerate(_high_insts_list):\n",
    "            _high_insts_list[idx]= _high_insts_list[idx].strip()\n",
    "\n",
    "        if '' in _high_insts_list:\n",
    "            while '' in _high_insts_list:\n",
    "                _high_insts_list.remove('')\n",
    "        \n",
    "        # If len(_high_inst_list) != generate_num, we assume the outputs are noisy and remove last 10 commands.\n",
    "        if len(_high_insts_list) != generate_num:\n",
    "            if len(_high_insts_list) != (generate_num-1):\n",
    "                print('The number of generated commands is not {} : {}.'.format(generate_num, len(_high_insts_list)))\n",
    "                print(\" I expect there is some issue in the output, so I only get the output without last 10 commands.\", end='\\n\\n')\n",
    "                if len(_high_insts_list) <= 10:\n",
    "                    print(\"the number of generated instruction is less than 10. Pass the generation and continue.\")\n",
    "                    print(\"current iter_num: \", iter_num)\n",
    "                    print(\"=============================================\", end='\\n\\n')\n",
    "                    iter_num-=1\n",
    "                    continue\n",
    "                else:\n",
    "                    _high_insts_list= _high_insts_list[:len(_high_insts_list)-10]\n",
    "\n",
    "        if iter_num%100 == 0:\n",
    "            print(\"Objects for {} generated {} {} {}\".format(commands_dict['place'],\\\n",
    "                                                                    len(commands_dict['prompt_output(high)']),\\\n",
    "                                                                   len(commands_dict['high_instructions']),\\\n",
    "                                                                   len(commands_dict['used_objects'])))\n",
    "\n",
    "        ### 2. Detect new objects used in generated commands, add them to object list, and shuffle object list\n",
    "        ins_objs, only_high_insts, noise_prompt= split_object_inst(_high_insts_list)\n",
    "        commands_dict['high_instructions'].extend(only_high_insts)\n",
    "        commands_dict['used_objects'].extend(ins_objs)\n",
    "        \n",
    "        if len(noise_prompt) >= 1:\n",
    "            for idx in noise_prompt:\n",
    "                _high_insts_list.remove(_high_insts_list[idx])\n",
    "                print(\"Remove \", _high_insts_list[idx])\n",
    "            print(\"Delete abnormal format's prompt output\")\n",
    "        print(len(_high_insts_list), len(only_high_insts), len(ins_objs)) \n",
    "        # Must be len(_high_insts_list) == len(only_high_insts) == len(ins_objs)\n",
    "\n",
    "        # Update object list\n",
    "        commands_dict['prompt_output(high)'].extend(_high_insts_list)\n",
    "    \n",
    "        spread_ins_objs= sum(ins_objs, [])\n",
    "        commands_dict['objects']= make_complete_objs(commands_dict['objects'], spread_ins_objs)  # format= list\n",
    "        random.shuffle(commands_dict['objects'])\n",
    "        \n",
    "        ### save file\n",
    "        with open(file_path+'/Commands.json', 'w') as instructions_file:\n",
    "            json.dump(commands_dict, instructions_file, indent='\\t')\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"\\'\\'\\'There is error in first iteration block. Ignore the error and continue the iteration.\")\n",
    "        print(\"Error message : \", ex)\n",
    "        print(\"Error iter_num : {}\\'\\'\\''\".format(iter_num), end='\\n\\n')\n",
    "        \n",
    "        iter_num-=1\n",
    "        continue\n",
    "\n",
    "print(\"Complete to generate high instructions {}\".format(len(commands_dict['high_instructions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict= dict()\n",
    "dataset_dict['place']= domain\n",
    "dataset_dict['objects']= commands_dict['objects']\n",
    "\n",
    "commands_final= list()\n",
    "steps= list()\n",
    "used_obj_list= list()\n",
    "i=0\n",
    "\n",
    "gpt_model = \"gpt-3.5-turbo-1106\"\n",
    "total_iter2= len(commands_dict['high_instructions'])\n",
    "\n",
    "print(\"total the number of high-level commands: \", total_iter2)\n",
    "print(\"Processed idx: \", end=' ')\n",
    "\n",
    "# second iteration block\n",
    "while True:\n",
    "    if i == total_iter2:\n",
    "        break\n",
    "\n",
    "    try: \n",
    "        # Split a high-level command and a objects list to input the action steps generating prompt\n",
    "        objs_on_table, high_inst, _ = split_object_inst([kitchen_insts_dict['prompt_output(high)'][i]])\n",
    "\n",
    "        high_inst= high_inst[0]\n",
    "        objs_on_table= objs_on_table[0]\n",
    "        print(objs_on_table, high_inst)\n",
    "        \n",
    "        if objs_on_table==0:\n",
    "            continue\n",
    "\n",
    "        prompt= steps_prompt.format(objs_on_table, high_inst)\n",
    "        generate_steps_messages = [\n",
    "                {\"role\": \"system\", \"content\": prompt}\n",
    "        ]    \n",
    "\n",
    "        steps_response = openai.ChatCompletion.create(\n",
    "            model=gpt_model,\n",
    "            messages=generate_steps_messages\n",
    "        )\n",
    "\n",
    "        _steps_i = steps_response['choices'][0]['message']['content']\n",
    "        _steps_i= _steps_i.strip()\n",
    "        \n",
    "        steps.append(_steps_i)\n",
    "        commands_final.append(high_inst)\n",
    "        used_obj_list.append(objs_on_table)\n",
    "\n",
    "        dataset_dict['prompt_output(steps)']= steps\n",
    "        dataset_dict['high_instructions']= commands_final\n",
    "        dataset_dict['used_objects']= used_obj_list\n",
    "\n",
    "        with open(file_path+'/_Dataset.json', 'w') as save_file:\n",
    "            json.dump(dataset_dict, save_file, indent='\\t')\n",
    "\n",
    "        i+=1\n",
    "        print(i, end=' ')\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(\"\\'\\'\\'There is error in second iteration block. Ignore the error and continue the iteration.\")\n",
    "        print(\"Error message : \", ex)\n",
    "        print(\"Error iter_num : {}\\'\\'\\''\".format(i), end='\\n\\n')\n",
    "        continue\n",
    "\n",
    "print(\"Complete generating steps for all high_instructions \", end=' ')\n",
    "print(len(dataset_dict['high_instructions']), len(dataset_dict['prompt_output(steps)']))\n",
    "# Must be len(dataset_dict['high_instructions']) == len(dataset_dict['prompt_output(steps)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(kitchen_insts_dict['objects']))\n",
    "print(len(kitchen_insts_dict['used_objects']))\n",
    "print(len(kitchen_insts_dict['prompt_output(high)']))\n",
    "print(len(kitchen_insts_dict['high_instructions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9cbca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_openai",
   "language": "python",
   "name": "for_openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
