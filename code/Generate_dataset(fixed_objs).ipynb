{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8408f5e4",
   "metadata": {},
   "source": [
    "* Make object list for Tabletop env refered from language table simulation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852105c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain= \"Tabletop\"\n",
    "\n",
    "color_list= ['green', 'red', 'yellow', 'blue']\n",
    "shape_list= ['star', 'moon', 'crescent', 'pentagon', 'square', 'circle', 'semicircle']\n",
    "block= 'block'\n",
    "cube= 'cube'\n",
    "bowl= \"bowl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c98d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_list= list()\n",
    "\n",
    "for color in color_list:\n",
    "    for shape in shape_list:\n",
    "        _obj= color + ' ' + shape + ' ' + block\n",
    "        objs_list.append(_obj)\n",
    "    _obj= color + ' '+ cube\n",
    "    objs_list.append(_obj)\n",
    "    \n",
    "    _obj= color + ' '+ bowl\n",
    "    objs_list.append(_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_dict= dict()\n",
    "objs_dict['place']= domain\n",
    "objs_dict['objects']= objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= './datasets/{}/objects.json'.format(domain)\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(objs_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2487a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef36727",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain= \"Tabletop\"\n",
    "OPENAI_API_KEY = # input your openai key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "gpt_model = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85902216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new objects that are out of object list\n",
    "def split_object_inst(org_objs, high_insts_list):    \n",
    "    ins_objs = list()\n",
    "    only_high_insts = list()\n",
    "    noise_prompt= list()\n",
    "    out_of_objs= False\n",
    "\n",
    "    for idx, high_inst in enumerate(high_insts_list): # each instruction\n",
    "        \n",
    "        parts = high_inst.strip()[1:].split(')')\n",
    "        out_of_objs= False\n",
    "        \n",
    "        if len(parts) != 2:\n",
    "            print(\"There is abnormal format at all: \", high_inst)\n",
    "            noise_prompt.append(idx)\n",
    "            continue\n",
    "            \n",
    "        # objects\n",
    "        _ins_objs= parts[0].split(',')\n",
    "        \n",
    "        if len(_ins_objs)< 2:\n",
    "            print(\"There is abnormal format in object: \", high_inst)\n",
    "            noise_prompt.append(idx)\n",
    "            continue\n",
    "        \n",
    "        for i, _objs in enumerate(_ins_objs):\n",
    "            _ins_objs[i]= re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', _objs).strip()\n",
    "        \n",
    "        # If new objects are used that is not in the objects list, the output is considered noise.\n",
    "        for _objs in _ins_objs:\n",
    "            if _objs.lower() not in org_objs:\n",
    "                print(\"There is objects that is out of object list: \", _objs)\n",
    "                out_of_objs= True\n",
    "                break\n",
    "                \n",
    "        if out_of_objs==True:\n",
    "            noise_prompt.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # commands\n",
    "        parts[1]= parts[1].strip()\n",
    "        parts[1]= re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', parts[1])\n",
    "        only_high_insts.append(parts[1])\n",
    "        ins_objs.append(_ins_objs)\n",
    "        \n",
    "    return ins_objs, only_high_insts, noise_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee971c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just split objects and command, and remove noise.\n",
    "def split_object_inst2(high_insts_list):\n",
    "    ins_objs = list()\n",
    "    only_high_insts = list()\n",
    "    noise_prompt= list()\n",
    "\n",
    "    for idx, high_inst in enumerate(high_insts_list): # each instruction\n",
    "        parts = high_inst.strip().split(')')\n",
    "            \n",
    "        # objects\n",
    "        __ins_objs= parts[0].strip()\n",
    "        _ins_objs= __ins_objs.split(',')\n",
    "\n",
    "        for i, _objs in enumerate(_ins_objs):\n",
    "            _ins_objs[i]= re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', _objs.strip()).strip()\n",
    "        \n",
    "        # If there are more than 3 tokens, don't consider it an object\n",
    "        noise= list()\n",
    "        for obj in _ins_objs:\n",
    "            if obj.strip() == '':\n",
    "                _ins_objs.remove(obj)\n",
    "                continue\n",
    "                \n",
    "            token_count= obj.split(\" \")\n",
    "            if len(token_count) > 3:\n",
    "                _ins_objs.remove(obj)\n",
    "        \n",
    "        if _ins_objs==[]:\n",
    "            noise_prompt.append(idx)\n",
    "            continue\n",
    "\n",
    "        ins_objs.append(_ins_objs)\n",
    "\n",
    "        # instruction\n",
    "        parts[1]= re.sub(r'^[^A-Za-z0-9]+|[^A-Za-z0-9]+$', '', parts[1].strip()).strip()\n",
    "        only_high_insts.append(parts[1])\n",
    "\n",
    "    return ins_objs, only_high_insts, noise_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99285f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= './prompt_templates/fixed_objects/Commands_generating_prompt.txt'\n",
    "with open(file_path, 'r') as prompt_file:\n",
    "    command_prompt= prompt_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ec281",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= './prompt_templates/fixed_objects/Action_steps_generating_prompt.txt'\n",
    "with open(file_path, 'r') as prompt_file:\n",
    "    steps_prompt= prompt_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read object list\n",
    "file_path= './datasets/{}/objects.json'.format(domain)\n",
    "with open(file_path, 'r') as objects_file:\n",
    "    block_objects= json.load(objects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc3350",
   "metadata": {},
   "source": [
    "----\n",
    "* Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_dict= dict()\n",
    "commands_dict['place']= domain\n",
    "commands_dict['objects']= block_objects['objects']\n",
    "\n",
    "sample_input1= '(Red cube, Yellow cube, Blue cube, Green cube), Place a cube of a different color in each corner.'\n",
    "high_insts_list=[sample_input1]\n",
    "commands_dict['prompt_output(high)']= high_insts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ef86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "iter_continue= True\n",
    "generate_num= 20\n",
    "dataset_size= 30000\n",
    "\n",
    "# First iteration block\n",
    "print(\"Start to generate high_instrctions\")\n",
    "while True:\n",
    "    try:\n",
    "        ### Iteration stop condition\n",
    "        if dataset_size <= len(commands_dict['high_instructions']):\n",
    "            break\n",
    "            \n",
    "        iter_num+=1\n",
    "        _high_insts_list= list()\n",
    "        \n",
    "        ### 1. Generate 20 high-level commands using objects list\n",
    "        random.shuffle(commands_dict['objects'])\n",
    "        prompt= command_prompt.format(generate_num, commands_dict['objects'], high_insts_list[0])\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]  \n",
    "\n",
    "        _response = openai.ChatCompletion.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages)\n",
    "        \n",
    "        _output = _response['choices'][0]['message']['content']\n",
    "        \n",
    "        # Output post-processing\n",
    "        _high_insts= _output.strip()\n",
    "        _high_insts= '2. '+ _high_insts\n",
    "\n",
    "        sentences = _high_insts.split('\\n')\n",
    "        sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "        _high_insts_list = [re.sub(r'^\\d+\\.\\s*', '', sentence) for sentence in sentences]\n",
    "        \n",
    "        for idx, inst in enumerate(_high_insts_list):\n",
    "            _high_insts_list[idx]= _high_insts_list[idx].strip()\n",
    "\n",
    "        if '' in _high_insts_list:\n",
    "            while '' in _high_insts_list:\n",
    "                _high_insts_list.remove('')\n",
    "        \n",
    "        # If len(_high_inst_list) != generate_num, we assume the outputs are noisy and remove last 10 commands.\n",
    "        if len(_high_insts_list) != generate_num:\n",
    "            if len(_high_insts_list) != (generate_num-1):\n",
    "                print('The number of generated commands is not {} : {}.'.format(generate_num, len(_high_insts_list)))\n",
    "                print(\" I expect there is some issue in the output, so I only get the output without last 10 sentences.\", end='\\n\\n')\n",
    "                if len(_high_insts_list) <= 10:\n",
    "                    print(\"the number of generated instruction is less than 10. Pass the generation and continue.\")\n",
    "                    print(\"current iter_num: \", iter_num)\n",
    "                    print(\"=================================\", end='\\n\\n')\n",
    "                    iter_num-=1\n",
    "                    continue\n",
    "                else:\n",
    "                    _high_insts_list= _high_insts_list[:len(_high_insts_list)-10]\n",
    "        \n",
    "        high_insts_list.extend(_high_insts_list)\n",
    "        commands_dict['prompt_output(high)']= high_insts_list\n",
    "\n",
    "        if iter_num%100 == 0:\n",
    "            print(\"Objects for {} generated (total {}) : {}\".format(commands_dict['place'], len(commands_dict['prompt_output(high)']), iter_num))\n",
    "    \n",
    "        ### 2. Detect new objects used in generated commands, remove them.\n",
    "        used_objs, only_high_insts, noise_prompt= split_object_inst(commands_dict['objects'],\\\n",
    "                                                         commands_dict['prompt_output(high)'])\n",
    "        commands_dict['high_instructions']= only_high_insts # format= list\n",
    "        commands_dict['used_objects']= used_objs\n",
    "        \n",
    "        if len(noise_prompt) >= 1:\n",
    "            for idx in noise_prompt:\n",
    "                del commands_dict['prompt_output(high)'][idx]\n",
    "            print(\"Delete abnormal format's prompt output\")\n",
    "        print(len(commands_dict['prompt_output(high)']), len(commands_dict['high_instructions']))\n",
    "        # Must be len(prompt_output) == len(high_instructions)\n",
    "\n",
    "        ### save file\n",
    "        with open(file_path+'/Commands.json', 'w') as instructions_file:\n",
    "            json.dump(commands_dict, instructions_file, indent='\\t')\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"\\'\\'\\'There is error in first iteration block. Ignore the error and continue the iteration.\")\n",
    "        print(\"Error message : \", ex)\n",
    "        print(\"Error iter_num : {}\\'\\'\\''\".format(iter_num), end='\\n\\n')\n",
    "        iter_num-=1\n",
    "        continue\n",
    "\n",
    "print(\"Complete to generate high instructions {}\".format(len(commands_dict['high_instructions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict= dict()\n",
    "dataset_dict['place']= domain\n",
    "dataset_dict['objects']= commands_dict['objects']\n",
    "_high_inst_list_for_final= list()\n",
    "steps= list()\n",
    "\n",
    "gpt_model = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "i=0\n",
    "total_iter2= len(commands_dict['high_instructions'])\n",
    "print(\"total the number of high_instructions: \", total_iter2)\n",
    "print(\"Processed idx: \", end=' ')\n",
    "\n",
    "# second iteration block\n",
    "while True:\n",
    "    if i == total_iter2:\n",
    "        break\n",
    "\n",
    "    try: \n",
    "        objs_on_table, high_inst, _ = split_object_inst2([commands_dict['prompt_output(high)'][i]])\n",
    "        objs_on_table= objs_on_table[0]\n",
    "        high_inst= high_inst[0]\n",
    "        print(objs_on_table, high_inst)\n",
    "\n",
    "        prompt= steps_prompt.format(objs_on_table, high_inst)\n",
    "        generate_steps_messages = [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "        ]    \n",
    "\n",
    "        steps_response = openai.ChatCompletion.create(\n",
    "            model=gpt_model,\n",
    "            messages=generate_steps_messages\n",
    "        )\n",
    "\n",
    "        _steps_i = steps_response['choices'][0]['message']['content']\n",
    "        _steps_i=  _steps_i.strip()\n",
    "\n",
    "        steps.append(_steps_i)\n",
    "        _high_inst_list_for_final.append(high_inst)\n",
    "\n",
    "        dataset_dict['prompt_output(steps)']= steps\n",
    "        dataset_dict['high_instructions']= _high_inst_list_for_final\n",
    "\n",
    "        with open(file_path+'/_Dataset.json', 'w') as save_file:\n",
    "            json.dump(dataset_dict, save_file, indent='\\t')\n",
    "\n",
    "        i+=1\n",
    "        print(i, end=' ')\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"\\'\\'\\'There is error in second iteration block. Ignore the error and continue the iteration.\")\n",
    "        print(\"Error message : \", ex)\n",
    "        print(\"Error iter_num : {}\\'\\'\\''\".format(i), end='\\n\\n')\n",
    "        continue\n",
    "\n",
    "print(\"Complete generating steps for all high_instructions \", end=' ')\n",
    "print(len(dataset_dict['high_instructions']), len(dataset_dict['prompt_output(steps)']))\n",
    "# Must be len(dataset_dict['high_instructions']) == len(dataset_dict['prompt_output(steps)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8bdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_openai",
   "language": "python",
   "name": "for_openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
